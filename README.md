# Реализация Пользовательского Пула Потоков

Этот проект реализует пользовательский пул потоков (`CustomThreadPool`) на языке Java, соответствующий интерфейсу `CustomExecutor`. Целью было создать пул потоков с настраиваемыми параметрами и пользовательской обработкой отклоненных задач, предоставляя больше контроля, чем стандартный `ThreadPoolExecutor`.

## Структура Проекта
com.example.customthreadpool <br>
├── CustomExecutor.java // Интерфейс<br>
├── CustomThreadPool.java // Реализация пула <br>
├── Worker.java // Рабочий поток <br>
├── ThreadFactoryImpl.java <br>
├── Main.java // Демонстрационная программа <br>
└── README.md<br>


## Параметры Конфигурации

`CustomThreadPool` поддерживает следующие параметры конфигурации:

*   `corePoolSize`: Минимальное количество потоков в пуле.
*   `maxPoolSize`: Максимальное количество потоков в пуле.
*   `keepAliveTime`: Время (в `timeUnit`), в течение которого простаивающие потоки будут ждать перед завершением.
*   `timeUnit`: Единица измерения времени для `keepAliveTime` (например, `TimeUnit.SECONDS`).
*   `queueSize`: Максимальное количество задач, которые могут быть поставлены в очередь.
*   `minSpareThreads`: Минимальное количество простаивающих потоков, которые необходимо поддерживать в живых, даже если пул используется недостаточно.

## Обработка Отклоненных Задач

Когда очередь задач заполнена и все потоки заняты, новые задачи отклоняются. Политика отклонения реализована непосредственно в методе `execute()` класса `CustomThreadPool`. Вместо использования `RejectedExecutionHandler` (который требует наследования от `ThreadPoolExecutor`, что не сделано в этой реализации), метод `execute()` включает логику для записи сообщения при отклонении задачи из-за переполнения очереди или остановки пула.

**Стратегии Отклонения:**

*   **Логирование:** Система записывает сообщение `SEVERE` при отклонении задачи, указывая на перегрузку.
*   **Альтернативные Стратегии (Закомментированы в Коде):**
    *   `Выброс RejectedExecutionException`: Это позволило бы вызывающему коду обрабатывать отклонение.
    *   `Выполнение задачи в текущем потоке`: Это позволило бы избежать отклонения задачи, но могло бы негативно повлиять на производительность вызывающего потока. (НЕ рекомендуется для систем с высокой нагрузкой).

## Распределение Задач

Задачи отправляются в одну `LinkedBlockingQueue`. Рабочие потоки извлекают задачи из этой очереди, используя подход `FIFO (Первый пришел - Первый ушел)`. В этой версии не реализован явный алгоритм балансировки. Потенциальным будущим улучшением может быть реализация распределения Round Robin или Least Loaded между несколькими очередями.

## Кастомизация

*   `ThreadFactory`: Пользовательская `ThreadFactoryImpl` присваивает потокам уникальные имена и регистрирует события создания потоков.
*   `Очередь задач`: Использует `LinkedBlockingQueue` с настраиваемым параметром `queueSize`.

## Интерфейс

Класс `CustomThreadPool` реализует интерфейс `CustomExecutor`, предоставляя следующие методы:

*   `execute(Runnable command)`: Выполняет заданную задачу `Runnable`.
*   `submit(Callable<T> task)`: Отправляет задачу `Callable` и возвращает `Future`, представляющий результат.
*   `shutdown()`: Инициирует упорядоченное завершение работы, позволяя выполняющимся в данный момент задачам завершиться.
*   `shutdownNow()`: Пытается остановить все активно выполняющиеся задачи и останавливает обработку ожидающих задач.

## Демонстрационная Программа

Класс `Main` демонстрирует использование `CustomThreadPool`:

*   Инициализирует пул с примерами параметров.
*   Отправляет в пул несколько задач, каждая из которых имитирует работу с помощью вызова `Thread.sleep()`.
*   Демонстрирует отклонение задач при перегрузке пула (путем отправки большего количества задач, чем может вместить очередь).
*   Вызывает `shutdown()` и проверяет, что все задачи завершены и потоки освобождены.

## Анализ Производительности

### Сравнение с `ThreadPoolExecutor`

Непосредственное сравнение со `ThreadPoolExecutor` требует тщательной настройки и учета сценария использования. В общем, `ThreadPoolExecutor` очень хорошо оптимизирован и протестирован. Эта пользовательская реализация может предложить преимущества в определенных сценариях, где:

*   **Настраиваемое именование и логирование потоков:** `ThreadFactoryImpl` предоставляет больше контроля над именованием и логированием потоков, чем стандартный `ThreadPoolExecutor`.
*   **Встроенная логика отклонения:** Непосредственный контроль над политиками отклонения в `CustomThreadPool` позволяет избежать проблем с ограничениями интерфейса (как видно из процесса разработки).

Однако стандартный `ThreadPoolExecutor`, скорее всего, превзойдет эту пользовательскую реализацию в большинстве общих сценариев благодаря своей более зрелой и оптимизированной конструкции.

### Настройка Параметров

Следующие параметры могут существенно повлиять на производительность:

*   `corePoolSize` и `maxPoolSize`: Меньший `corePoolSize` может привести к недоиспользованию ресурсов, а больший `maxPoolSize` может привести к чрезмерному созданию потоков и переключению контекста. Оптимальные значения зависят от количества доступных ядер и характера задач.
*   `keepAliveTime`: Более короткий `keepAliveTime` быстрее освободит простаивающие потоки, экономя ресурсы. Более длинный `keepAliveTime` будет дольше поддерживать потоки в живых, потенциально снижая накладные расходы на создание потоков, если задачи поступают часто.
*   `queueSize`: Небольшой `queueSize` приведет к частому отклонению задач, а большой `queueSize` может привести к увеличению задержки, поскольку задачи ожидают в очереди. Оптимальное значение зависит от скорости поступления и времени выполнения задач. `queueSize`, равный 0, может быть полезен для немедленного выполнения, а очень большой `queueSize` аналогичен неограниченной очереди.
*   `minSpareThreads`: Более высокое значение может поддерживать больше потоков активными даже при низкой нагрузке. Слишком высокое значение может привести к пустой трате ресурсов.

### Механизм Распределения Задач

В текущей реализации используется одна `LinkedBlockingQueue` для распределения задач. Это приводит к порядку обработки FIFO (Первым пришел - Первым ушел). Хотя это просто, этот подход может быть неоптимальным для всех рабочих нагрузок. Будущие улучшения могут включать:

*   **Несколько очередей с распределением Round Robin или Least Loaded:** Это обеспечило бы лучшую балансировку нагрузки между рабочими потоками.
*   **Очередь с приоритетами:** Это позволило бы приоритизировать определенные задачи над другими.
